{
 "metadata": {
  "name": "",
  "signature": "sha256:db41c7a2a169c67072a363b9f89ce5137f84f2d5cfca1a7d4c645989b33cad06"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<small><i>This notebook was put together by [Roman Prokofyev](http://prokofyev.ch)@[eXascale Infolab](http://exascale.info/). Source and license info is on [GitHub](https://github.com/dragoon/kilogram/).</i></small>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<small>\n",
      "This notebook is a part of bigger tutorial on fixing grammatical edits.\n",
      "\n",
      "* **[Part 1: Extracting edits from StackExchange Data](http://nbviewer.ipython.org/github/dragoon/dataset-utils/blob/master/notebooks/stackexchange_edit_extraction.ipynb)**\n",
      "* [Part 2: Processing Google Book N-grams dataset](http://nbviewer.ipython.org/github/dragoon/kilogram/blob/master/notebooks/process_google_ngrams.ipynb)\n",
      "* [Part 3: Computing association measures between words](http://nbviewer.ipython.org/github/dragoon/kilogram/blob/master/notebooks/pmi_association_measures.ipynb)\n",
      "* [Part 4: Generic data analysis](http://nbviewer.ipython.org/github/dragoon/kilogram/blob/master/notebooks/data_analysis_generic.ipynb)\n",
      "* [Part 5: Machine learning to fix grammar](http://nbviewer.ipython.org/github/dragoon/kilogram/blob/master/notebooks/ml_grammar.ipynb)\n",
      "</small>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Prerequisites\n",
      "\n",
      "You will need to install the following python packages to run the notebook:\n",
      "\n",
      "* sudo apt-get install libxml2-dev libxslt-dev (to compile lxml)\n",
      "* pip install nltk\n",
      "* pip install pandas\n",
      "* pip install -U https://github.com/dragoon/kilogram/zipball/master"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Step 0: Downloading StackExchange data\n",
      "\n",
      "Download from: https://archive.org/details/stackexchange.\n",
      "\n",
      "Each file in the downloaded archives is a 7z archive that contains file ``PostHistory.xml`` inside. For this example, I have upacked the **travel forum** archive and renamed history XML to ``travel_post_history.xml``."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Step 1: Processing XML edit history files\n",
      "\n",
      "Now we are going to extract all edits that had the word **\"grammar\"** in the comment field, implying that a user have fixed grammar of a post by this edit:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import subprocess\n",
      "print subprocess.check_output(\"se_parse_edit_history.py -o /home/roman/travel.tsv /home/roman/travel_post_history.xml; exit 0\",\n",
      "                              shell=True, stderr=subprocess.STDOUT)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing XML /home/roman/travel_post_history.xml ...\n",
        "Sorting...\n",
        "Filtering edits...\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use pandas to look at our data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame, read_csv, isnull\n",
      "import pandas as pd\n",
      "df = read_csv('/home/roman/travel.tsv', sep='\\t', names=('text1', 'text2'))\n",
      "df.head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>text1</th>\n",
        "      <th>text2</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> My finance and myself are looking for a good C...</td>\n",
        "      <td> My fiance and I are looking for a good Caribbe...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>     What's are some Caribbean cruises for October</td>\n",
        "      <td>      What are some Caribbean cruises for October?</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> I am looking for am exhaustive and light set o...</td>\n",
        "      <td> I am looking for an exhaustive and light set o...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> November is very much off-season for Disney - ...</td>\n",
        "      <td> November is very much off-season for Disney - ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> As homebase choose Irkutsk. Travel to Olkhon i...</td>\n",
        "      <td> Choose Irkutsk as home base. Travel to Olkhon ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> I live in Poland and I would like to take my c...</td>\n",
        "      <td> I live in Poland and I would like to take my c...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 1) To avoid that you're laptop is stolen I wou...</td>\n",
        "      <td> 1) To avoid your laptop from being stolen I wo...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> Not sure if this is quite the scenario you are...</td>\n",
        "      <td> Not sure if this is quite the scenario you are...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> While going to India via Emirates, i am planni...</td>\n",
        "      <td> While going to India via Emirates, I am planni...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> Is the first time I post in this forum but I n...</td>\n",
        "      <td> I have been accepted as student for the 2013 J...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>10 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "                                               text1  \\\n",
        "0  My finance and myself are looking for a good C...   \n",
        "1      What's are some Caribbean cruises for October   \n",
        "2  I am looking for am exhaustive and light set o...   \n",
        "3  November is very much off-season for Disney - ...   \n",
        "4  As homebase choose Irkutsk. Travel to Olkhon i...   \n",
        "5  I live in Poland and I would like to take my c...   \n",
        "6  1) To avoid that you're laptop is stolen I wou...   \n",
        "7  Not sure if this is quite the scenario you are...   \n",
        "8  While going to India via Emirates, i am planni...   \n",
        "9  Is the first time I post in this forum but I n...   \n",
        "\n",
        "                                               text2  \n",
        "0  My fiance and I are looking for a good Caribbe...  \n",
        "1       What are some Caribbean cruises for October?  \n",
        "2  I am looking for an exhaustive and light set o...  \n",
        "3  November is very much off-season for Disney - ...  \n",
        "4  Choose Irkutsk as home base. Travel to Olkhon ...  \n",
        "5  I live in Poland and I would like to take my c...  \n",
        "6  1) To avoid your laptop from being stolen I wo...  \n",
        "7  Not sure if this is quite the scenario you are...  \n",
        "8  While going to India via Emirates, I am planni...  \n",
        "9  I have been accepted as student for the 2013 J...  \n",
        "\n",
        "[10 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check for **NULL** values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check for None values\n",
      "print [i for i, x in enumerate(isnull(df['text1'])) if x]\n",
      "df.iloc[210]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[210]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "text1                                                  NaN\n",
        "text2    A country in the Caucasus region bordering [ta...\n",
        "Name: 210, dtype: object"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since our data is not numeric, we are not going to use dataframes for iteration:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data looks good, now let's continue to extracting specific edits."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Step 2: Edit extraction\n",
      "\n",
      "The following processed every edit made by users and extracts specific tokens that were changed.\n",
      "It can be one or more words:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from kilogram import extract_edits\n",
      "edits = extract_edits('/home/roman/travel.tsv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total edits extracted: 1334\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print edits[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "finance\u2192fiance\n",
        "My fiance and I are\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's filter only edits that altered prepositions, for this I have prepared a small file with a set of prepositions to consider.\n",
      "\n",
      "You can find the file here: https://github.com/dragoon/kilogram/blob/master/extra/preps.txt"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PREPS_1GRAM = set(open('/home/roman/ngrams_data/preps.txt').read().split('\\n'))\n",
      "prep_edits = [x for x in edits if x.edit1 in PREPS_1GRAM and x.edit2 in PREPS_1GRAM]\n",
      "print ', '.join([x.edit1+u'\u2192'+x.edit2 for x in prep_edits])\n",
      "print\n",
      "print prep_edits[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "of\u2192off, towards\u2192of, on\u2192in, on\u2192in, on\u2192in, on\u2192of, off\u2192of, at\u2192on, in\u2192on, through\u2192with, in\u2192around, at\u2192in, on\u2192of, on\u2192of, at\u2192on, in\u2192at, on\u2192in, for\u2192at, in\u2192during, on\u2192in, of\u2192over, of\u2192off, to\u2192into, on\u2192in, from\u2192of, in\u2192on, in\u2192of, of\u2192off, on\u2192in, for\u2192with, from\u2192of, on\u2192in, to\u2192into, at\u2192in, for\u2192on, for\u2192in, in\u2192at, at\u2192in, than\u2192from, in\u2192at, of\u2192off, for\u2192over, into\u2192in\n",
        "\n",
        "on\u2192in\n",
        "the biggest building in the world .\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each edit represents an object of type ``kilogram.edit.Edit`` and you can retrieve the following info from it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print prep_edits[2].text1\n",
      "print\n",
      "print prep_edits[2].text2\n",
      "print prep_edits[2].edit1, prep_edits[2].edit2\n",
      "print\n",
      "print str(prep_edits[2].tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Today I saw a picture of a building that claims to be the biggest building on the whole world . I really doubt that , but the problem is , I couldn't verify it![enter image description here][1.It is somewhere in Eastern Europe , probably a capital . So where should I travel to , when I want to see this building . [ 1 ] : http://i.stack.imgur.com/VbPEl.jpg\n",
        "\n",
        "Today I saw a picture of a building that claims to be the biggest building in the world . I really doubt that , but the problem is , I couldn't verify it . Here it is![enter image description here][1.It is somewhere in Eastern Europe , probably a capital . So where should I travel to , when I want to see this building . [ 1 ] : http://i.stack.imgur.com/VbPEl.jpg\n",
        "on in\n",
        "\n",
        "[u'Today', u'I', u'saw', u'a', u'picture', u'of', u'a', u'building', u'that', u'claims', u'to', u'be', u'the', u'biggest', u'building', u'in', u'the', u'world', u'.', u'I', u'really', u'doubt', u'that', u',', u'but', u'the', u'problem', u'is', u',', u'I', u\"couldn't\", u'verify', u'it', u'.', u'Here', u'it', u'is![enter', u'image', u'description', u'here][1.It', u'is', u'somewhere', u'in', u'Eastern', u'Europe', u',', u'probably', u'a', u'capital', u'.', u'So', u'where', u'should', u'I', u'travel', u'to', u',', u'when', u'I', u'want', u'to', u'see', u'this', u'building', u'.', u'[', u'1', u']', u':', u'http://i.stack.imgur.com/VbPEl.jpg']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also possible to retrieve **n-gram contexts** of a specified size around the edit:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print prep_edits[2].ngram_context(size=2)\n",
      "print prep_edits[2].ngram_context(size=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{2: [building in, in the]}\n",
        "{2: [building in, in the], 3: [biggest building in, building in the, in the world]}\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next part of this notebook describes how to process Google Books N-gram corpus in order to calculate association measures between words which we are going to use to fix grammar."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}