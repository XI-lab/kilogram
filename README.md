[![DOI](https://zenodo.org/badge/7837/dragoon/kilogram.svg)](http://dx.doi.org/10.5281/zenodo.13261)
# Kilogram
### Collection of utils for large n-gram corpora

### Available dataset parsers:

* StackExchange data dumps
* Wikipedia edit history dumps, can be downloaded from http://dumps.wikimedia.org/enwiki/latest/.
  This library works with enwiki-20140707-pages-meta-history*.7z files.
* [First Certificate of English (FCE) collection](http://ilexir.co.uk/applications/clc-fce-dataset/)

Tutorials here:

 * [Part 1: Extracting edits from StackExchange Data](http://nbviewer.ipython.org/github/dragoon/kilogram/blob/master/notebooks/stackexchange_edit_extraction.ipynb)
 * [Part 2: Processing Google Book N-grams dataset](http://nbviewer.ipython.org/github/dragoon/kilogram/blob/master/notebooks/process_google_ngrams.ipynb)
 * [Part 3: Computing association measures between words](http://nbviewer.ipython.org/github/dragoon/kilogram/blob/master/notebooks/pmi_association_measures.ipynb)
 * [Part 4: Data analysis](http://nbviewer.ipython.org/github/dragoon/kilogram/blob/master/notebooks/data_analysis_generic.ipynb)
 * [Part 4: Machine learning for grammar correction](http://nbviewer.ipython.org/github/dragoon/kilogram/blob/master/notebooks/ml_grammar.ipynb)
